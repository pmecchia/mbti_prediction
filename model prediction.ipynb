{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MBTI PREDICTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Myersâ€“Briggs Type Indicator (MBTI) is an introspective self-report questionnaire indicating differing psychological preferences in how people perceive the world and make decisions. \n",
    "The test attempts to assign four categories:\n",
    "\n",
    "   * introversion or extraversion \n",
    "   * sensing or intuition \n",
    "   * thinking or feeling \n",
    "   * judging or perceiving\n",
    "  \n",
    "One letter from each category is taken to produce a four-letter test result, like \"INFJ\" or \"ENFP\".\n",
    "\n",
    "Source: <a href=\"https://en.wikipedia.org/wiki/Myers%E2%80%93Briggs_Type_Indicator\" target=\"_blank\">https://en.wikipedia.org/wiki/Myers%E2%80%93Briggs_Type_Indicator</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: <a href=\"https://www.kaggle.com/datasnaek/mbti-type\" target=\"_blank\">https://www.kaggle.com/datasnaek/mbti-type</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"mbti_dataset.csv\",encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4  ENTJ  'You're fired.|||That's another silly misconce..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Labels enconding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = df[\"type\"].unique()\n",
    "for idx,mbti in enumerate(types):\n",
    "    df[\"type\"]= df[\"type\"].replace(mbti,idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preprocessing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "#create an object of class PorterStemmer\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanData(posts):\n",
    "    # Lowercase\n",
    "    clean_text = posts.lower()\n",
    "    #remove all hyperlinks\n",
    "    clean_text = re.sub(r'(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})','',clean_text)\n",
    "    word_list = word_tokenize(clean_text)\n",
    "    clean_posts = []\n",
    "    for word in word_list:\n",
    "        if word.isalpha() and word not in stop_words:\n",
    "            word = porter.stem(word)\n",
    "            clean_posts.append(word)\n",
    "    return clean_posts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"posts_preprocessed\"]= df[\"posts\"].apply(lambda row: cleanData(row))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing data analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We group the posts with the same type in order to detect the most used commun words for each type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts_grouped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[intj, moment, sportscent, top, ten, play, exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[find, lack, post, bore, posit, often, exampl,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[one, cours, say, know, bless, absolut, posit,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[intp, enjoy, convers, day, esoter, gab, natur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[anoth, silli, misconcept, approach, logic, go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>[went, break, month, ago, togeth, year, plan, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[think, agre, person, consid, alpha, beta, fox...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>[want, go, trip, without, stay, behind, would,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>[paint, without, guess, istp, best, bud, esfp,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>[got, read, enneagram, though, read, somewher,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>[love, feel, affection, one, love, care, care,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>[univers, graviti, law, mean, serious, would, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>[splinter, cell, blacklist, xbox, gener, well,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>[forgot, board, current, read, fowl, etern, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>[catch, although, quit, terribl, estj, fi, dev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>[esfj, origin, mistyp, nfp, think, increasingl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type                                      posts_grouped\n",
       "0      0  [intj, moment, sportscent, top, ten, play, exp...\n",
       "1      1  [find, lack, post, bore, posit, often, exampl,...\n",
       "2      2  [one, cours, say, know, bless, absolut, posit,...\n",
       "3      3  [intp, enjoy, convers, day, esoter, gab, natur...\n",
       "4      4  [anoth, silli, misconcept, approach, logic, go...\n",
       "5      5  [went, break, month, ago, togeth, year, plan, ...\n",
       "6      6  [think, agre, person, consid, alpha, beta, fox...\n",
       "7      7  [want, go, trip, without, stay, behind, would,...\n",
       "8      8  [paint, without, guess, istp, best, bud, esfp,...\n",
       "9      9  [got, read, enneagram, though, read, somewher,...\n",
       "10    10  [love, feel, affection, one, love, care, care,...\n",
       "11    11  [univers, graviti, law, mean, serious, would, ...\n",
       "12    12  [splinter, cell, blacklist, xbox, gener, well,...\n",
       "13    13  [forgot, board, current, read, fowl, etern, co...\n",
       "14    14  [catch, although, quit, terribl, estj, fi, dev...\n",
       "15    15  [esfj, origin, mistyp, nfp, think, increasingl..."
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped = df.groupby('type')['posts_preprocessed'].apply(list).reset_index(name='posts_grouped')\n",
    "df_grouped['posts_grouped'] = df_grouped['posts_grouped'].apply(lambda row: [y for x in row for y in x]) # Flatten list\n",
    "df_grouped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_important_words(post_preprocessed):\n",
    "    \n",
    "    w=dict.fromkeys(post_preprocessed,0)\n",
    "    for i in post_preprocessed:\n",
    "        w[i]=w[i]+1\n",
    "    data_sorted = {k: v for k, v in sorted(w.items(), key=lambda x: x[1],reverse=True)}\n",
    "    return data_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We create a descending order dictionnary: each word as a key and the number of accurrences as a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     {'like': 12861, 'think': 10235, 'peopl': 8405,...\n",
       "1     {'like': 5805, 'think': 4563, 'peopl': 3602, '...\n",
       "2     {'like': 10546, 'think': 8421, 'peopl': 6831, ...\n",
       "3     {'like': 8517, 'think': 6513, 'peopl': 5759, '...\n",
       "4     {'like': 1846, 'think': 1471, 'peopl': 1181, '...\n",
       "5     {'like': 1759, 'think': 1396, 'peopl': 1169, '...\n",
       "6     {'like': 16990, 'think': 12980, 'peopl': 10261...\n",
       "7     {'like': 6501, 'think': 4633, 'enfp': 3779, 'p...\n",
       "8     {'like': 2541, 'think': 1766, 'realli': 1288, ...\n",
       "9     {'like': 2696, 'think': 1965, 'get': 1732, 'pe...\n",
       "10    {'like': 1534, 'think': 1216, 'isfj': 930, 'pe...\n",
       "11    {'like': 1798, 'think': 1226, 'istj': 939, 'pe...\n",
       "12    {'like': 803, 'think': 564, 'get': 514, 'estp'...\n",
       "13    {'like': 380, 'think': 292, 'peopl': 220, 'kno...\n",
       "14    {'like': 292, 'think': 269, 'estj': 213, 'peop...\n",
       "15    {'like': 411, 'esfj': 365, 'think': 352, 'peop...\n",
       "Name: dictionnary, dtype: object"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped['dictionnary'] = df_grouped['posts_grouped'].apply(lambda row: select_important_words(row))\n",
    "df_grouped[\"dictionnary\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We select the 20 most frequent words for each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [like, think, peopl, feel, infj, know, one, ge...\n",
       "1     [like, think, peopl, entp, one, get, would, kn...\n",
       "2     [like, think, peopl, would, one, intp, get, kn...\n",
       "3     [like, think, peopl, intj, would, one, know, g...\n",
       "4     [like, think, peopl, entj, get, would, one, kn...\n",
       "5     [like, think, peopl, feel, enfj, know, get, re...\n",
       "6     [like, think, peopl, feel, realli, know, infp,...\n",
       "7     [like, think, enfp, peopl, know, get, feel, re...\n",
       "8     [like, think, realli, peopl, feel, get, know, ...\n",
       "9     [like, think, get, peopl, would, know, istp, o...\n",
       "10    [like, think, isfj, peopl, get, would, know, r...\n",
       "11    [like, think, istj, peopl, would, get, know, o...\n",
       "12    [like, think, get, estp, peopl, know, one, typ...\n",
       "13    [like, think, peopl, know, get, realli, would,...\n",
       "14    [like, think, estj, peopl, would, know, get, o...\n",
       "15    [like, esfj, think, peopl, type, know, get, fe...\n",
       "Name: most_frequent_words, dtype: object"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped[\"most_frequent_words\"]=df_grouped[\"dictionnary\"].apply(lambda row: list(row.keys())[0:20])\n",
    "df_grouped[\"most_frequent_words\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We group the most frequent words for all type and create a dictionnary with occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'like': 15,\n",
       "         'think': 15,\n",
       "         'peopl': 15,\n",
       "         'feel': 15,\n",
       "         'infj': 1,\n",
       "         'know': 15,\n",
       "         'one': 15,\n",
       "         'get': 15,\n",
       "         'would': 15,\n",
       "         'realli': 15,\n",
       "         'thing': 15,\n",
       "         'time': 15,\n",
       "         'say': 15,\n",
       "         'person': 14,\n",
       "         'go': 15,\n",
       "         'make': 15,\n",
       "         'want': 15,\n",
       "         'love': 7,\n",
       "         'type': 14,\n",
       "         'much': 7,\n",
       "         'entp': 1,\n",
       "         'see': 7,\n",
       "         'way': 1,\n",
       "         'intp': 1,\n",
       "         'use': 2,\n",
       "         'intj': 1,\n",
       "         'entj': 1,\n",
       "         'good': 1,\n",
       "         'enfj': 1,\n",
       "         'friend': 6,\n",
       "         'infp': 1,\n",
       "         'enfp': 1,\n",
       "         'isfp': 1,\n",
       "         'istp': 1,\n",
       "         'someth': 1,\n",
       "         'isfj': 1,\n",
       "         'istj': 1,\n",
       "         'estp': 1,\n",
       "         'esfp': 1,\n",
       "         'estj': 1})"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total=[]\n",
    "for i in range(0,len(types)-1):\n",
    "    total = total + df_grouped[\"most_frequent_words\"][i]\n",
    "most_freq_dict=Counter(total)\n",
    "most_freq_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the word \"like\" is one of the most frequent words for the 15 types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We create a list with the words which appear as a one of the most frequent words for at least 11 types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['like',\n",
       " 'think',\n",
       " 'peopl',\n",
       " 'feel',\n",
       " 'know',\n",
       " 'one',\n",
       " 'get',\n",
       " 'would',\n",
       " 'realli',\n",
       " 'thing',\n",
       " 'time',\n",
       " 'say',\n",
       " 'person',\n",
       " 'go',\n",
       " 'make',\n",
       " 'want',\n",
       " 'love',\n",
       " 'type',\n",
       " 'much',\n",
       " 'see']"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_delete=[]\n",
    "for i in most_freq_dict:\n",
    "    if most_freq_dict[i]>6:\n",
    "        words_to_delete.append(i)\n",
    "words_to_delete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Filtering preprocessing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"posts_preprocessed_filtered\"]= df[\"posts_preprocessed\"].apply(lambda row: [w for w in row if not w in words_to_delete])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [intj, moment, sportscent, top, ten, play, exp...\n",
       "1       [find, lack, post, bore, posit, often, exampl,...\n",
       "2       [cours, bless, absolut, posit, best, friend, c...\n",
       "3       [intp, enjoy, convers, day, esoter, gab, natur...\n",
       "4       [anoth, silli, misconcept, approach, logic, ke...\n",
       "5       [perfect, scientist, claim, scientif, inform, ...\n",
       "6       [ca, draw, nail, haha, done, profession, nail,...\n",
       "7       [tend, build, collect, desktop, use, frequent,...\n",
       "8       [sure, good, question, distinct, two, depend, ...\n",
       "9       [posit, actual, let, due, variou, reason, unfo...\n",
       "10      [parent, fight, dad, affair, dad, push, mom, f...\n",
       "11      [went, break, month, ago, togeth, year, plan, ...\n",
       "12      [santagato, entp, sure, infj, heavi, fi, viole...\n",
       "13      [enough, look, state, incred, naiv, comment, h...\n",
       "14      [cheezburgr, fond, top, hat, certainli, expect...\n",
       "15      [comment, scream, intj, bro, especi, useless, ...\n",
       "16      [excit, calm, butt, bodi, brain, commun, garde...\n",
       "17      [agre, consid, alpha, beta, foxtrot, lol, joke...\n",
       "18      [fulli, believ, power, protector, give, voic, ...\n",
       "19      [normal, happen, also, high, mood, act, depres...\n",
       "20      [job, recogn, strive, effici, practic, geniu, ...\n",
       "21      [annoy, misinterpret, especi, regard, core, in...\n",
       "22      [interest, lazi, research, club, mate, profil,...\n",
       "23      [urh, sorri, uh, could, enfj, pleas, collect, ...\n",
       "24      [strong, two, year, mark, made, notic, chang, ...\n",
       "25      [sj, job, issu, back, find, job, could, job, a...\n",
       "26      [trip, without, stay, behind, option, believ, ...\n",
       "27      [paint, without, guess, istp, best, bud, esfp,...\n",
       "28      [main, question, believ, valu, matter, sorri, ...\n",
       "29      [absolut, true, infj, shame, potenti, depart, ...\n",
       "                              ...                        \n",
       "8645    [play, cello, also, classic, train, soprano, p...\n",
       "8646    [less, base, experienc, life, teen, earli, var...\n",
       "8647    [socion, pick, call, visual, identif, also, th...\n",
       "8648    [advic, thank, tough, situat, right, could, us...\n",
       "8649    [enjoy, let, stop, kick, walk, stick, tskkk, l...\n",
       "8650    [real, question, whether, infj, neat, domin, f...\n",
       "8651    [alon, insensit, servic, earn, incom, catalyst...\n",
       "8652    [assert, stand, someth, struggl, day, worri, n...\n",
       "8653    [whatev, privat, mayb, meant, facebook, learn,...\n",
       "8654    [hand, alway, least, consid, possibl, culpabl,...\n",
       "8655    [find, poster, facial, express, along, fact, i...\n",
       "8656    [rim, approxim, order, seem, decis, right, wro...\n",
       "8657    [social, gener, posit, associ, idea, part, som...\n",
       "8658    [worri, car, come, close, behind, least, chang...\n",
       "8659    [bad, social, anxieti, took, medicin, huge, ad...\n",
       "8660    [vast, sky, problem, sad, alway, seem, granula...\n",
       "8661    [log, read, post, month, catch, everyth, black...\n",
       "8662    [ca, specif, belief, mean, limit, simpl, code,...\n",
       "8663    [matter, choic, elect, dave, johnson, death, p...\n",
       "8664    [mani, tie, groundhog, day, good, ah, play, we...\n",
       "8665    [test, even, close, gender, age, mbti, check, ...\n",
       "8666    [recommend, tri, listen, asian, music, korean,...\n",
       "8667    [gener, experi, post, trauma, similar, way, se...\n",
       "8668    [plan, stress, reliev, activ, work, last, day,...\n",
       "8669    [sure, method, pick, infj, music, artist, anot...\n",
       "8670    [alway, cat, fi, dom, reason, websit, becom, n...\n",
       "8671    [thread, alreadi, exist, someplac, els, heck, ...\n",
       "8672    [mani, question, take, purpl, pill, pick, win,...\n",
       "8673    [conflict, right, come, children, honestli, ma...\n",
       "8674    [long, sinc, personalitycaf, although, seem, c...\n",
       "Name: posts_preprocessed_filtered, Length: 8675, dtype: object"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"posts_preprocessed_filtered\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Vectorization**\n",
    "\n",
    " * CountVectorizer\n",
    " * TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[\"posts_preprocessed\"].map(' '.join)\n",
    "y=df[\"type\"]\n",
    "\n",
    "cnt_vector = cv.fit_transform(X)\n",
    "X_train,X_test,y_train,y_test = train_test_split(cnt_vector,y,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vector = tfidf.fit_transform(X)\n",
    "X_train_tfidf,X_test_tfidf,y_train_tfidf,y_test_tfidf = train_test_split(tfidf_vector,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filtered=df[\"posts_preprocessed_filtered\"].map(' '.join)\n",
    "\n",
    "tfidf_vector_filtered = tfidf.fit_transform(X_filtered)\n",
    "X_train_tfidf_filtered,X_test_tfidf_filtered,y_train_tfidf_filtered,y_test_tfidf_filtered = train_test_split(tfidf_vector_filtered,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Prediction***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 1:** Preprocessed data + CountVectorizer + LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:                precision    recall  f1-score   support\n",
      "\n",
      "        INFJ       0.53      0.57      0.55       294\n",
      "        ENTP       0.54      0.47      0.50       148\n",
      "        INTP       0.54      0.57      0.55       264\n",
      "        INTJ       0.47      0.53      0.50       203\n",
      "        ENTJ       0.52      0.31      0.39        52\n",
      "        ENFJ       0.36      0.27      0.31        45\n",
      "        INFP       0.60      0.65      0.63       342\n",
      "        ENFP       0.48      0.52      0.50       133\n",
      "        ISFP       0.42      0.40      0.41        48\n",
      "        ISTP       0.49      0.49      0.49        70\n",
      "        ISFJ       0.50      0.42      0.46        40\n",
      "        ISTJ       0.38      0.21      0.27        47\n",
      "        ESTP       0.50      0.24      0.32        21\n",
      "        ESFP       0.17      0.11      0.13         9\n",
      "        ESTJ       0.67      0.17      0.27        12\n",
      "        ESFJ       0.25      0.29      0.27         7\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      1735\n",
      "   macro avg       0.46      0.39      0.41      1735\n",
      "weighted avg       0.52      0.52      0.52      1735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC().fit(X_train,y_train)\n",
    "\n",
    "predictions=model.predict(X_test)\n",
    "\n",
    "acc = metrics.classification_report(y_test,predictions, target_names= types)\n",
    "\n",
    "\n",
    "print(\"accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 2:** Preprocessed data + TfidfVectorizer + LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:                precision    recall  f1-score   support\n",
      "\n",
      "        INFJ       0.61      0.71      0.65       279\n",
      "        ENTP       0.66      0.65      0.66       126\n",
      "        INTP       0.66      0.68      0.67       265\n",
      "        INTJ       0.59      0.65      0.62       222\n",
      "        ENTJ       0.76      0.38      0.51        50\n",
      "        ENFJ       0.70      0.36      0.47        39\n",
      "        INFP       0.70      0.79      0.74       398\n",
      "        ENFP       0.53      0.58      0.55       113\n",
      "        ISFP       0.54      0.38      0.45        50\n",
      "        ISTP       0.71      0.58      0.64        71\n",
      "        ISFJ       0.75      0.53      0.62        40\n",
      "        ISTJ       0.67      0.32      0.43        44\n",
      "        ESTP       0.83      0.29      0.43        17\n",
      "        ESFP       0.00      0.00      0.00         9\n",
      "        ESTJ       1.00      0.17      0.29         6\n",
      "        ESFJ       0.50      0.17      0.25         6\n",
      "\n",
      "   micro avg       0.64      0.64      0.64      1735\n",
      "   macro avg       0.64      0.45      0.50      1735\n",
      "weighted avg       0.65      0.64      0.63      1735\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierremecchia/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC().fit(X_train_tfidf,y_train_tfidf)\n",
    "\n",
    "predictions2=model.predict(X_test_tfidf)\n",
    "\n",
    "acc2 = metrics.classification_report(y_test_tfidf,predictions2, target_names= types)\n",
    "\n",
    "\n",
    "print(\"accuracy: \", acc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 3:** Filtered Preprocessed data + TfidfVectorizer + LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:                precision    recall  f1-score   support\n",
      "\n",
      "        INFJ       0.59      0.69      0.64       292\n",
      "        ENTP       0.61      0.52      0.56       132\n",
      "        INTP       0.63      0.75      0.68       251\n",
      "        INTJ       0.64      0.64      0.64       229\n",
      "        ENTJ       0.66      0.53      0.58        40\n",
      "        ENFJ       0.57      0.33      0.42        36\n",
      "        INFP       0.70      0.78      0.74       387\n",
      "        ENFP       0.62      0.58      0.60       132\n",
      "        ISFP       0.61      0.38      0.47        52\n",
      "        ISTP       0.74      0.55      0.63        67\n",
      "        ISFJ       0.86      0.50      0.63        24\n",
      "        ISTJ       0.52      0.33      0.40        43\n",
      "        ESTP       0.58      0.37      0.45        19\n",
      "        ESFP       0.00      0.00      0.00         7\n",
      "        ESTJ       0.67      0.14      0.24        14\n",
      "        ESFJ       0.83      0.50      0.62        10\n",
      "\n",
      "   micro avg       0.64      0.64      0.64      1735\n",
      "   macro avg       0.61      0.47      0.52      1735\n",
      "weighted avg       0.64      0.64      0.63      1735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC().fit(X_train_tfidf_filtered,y_train_tfidf_filtered)\n",
    "\n",
    "predictions_filtered=model.predict(X_test_tfidf_filtered)\n",
    "\n",
    "acc_filtered = metrics.classification_report(y_test_tfidf_filtered,predictions_filtered, target_names= types)\n",
    "\n",
    "\n",
    "print(\"accuracy: \", acc_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
