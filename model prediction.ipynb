{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MBTI PREDICTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Myersâ€“Briggs Type Indicator (MBTI) is an introspective self-report questionnaire indicating differing psychological preferences in how people perceive the world and make decisions. \n",
    "The test attempts to assign four categories:\n",
    "\n",
    "   * introversion or extraversion \n",
    "   * sensing or intuition \n",
    "   * thinking or feeling \n",
    "   * judging or perceiving\n",
    "  \n",
    "One letter from each category is taken to produce a four-letter test result, like \"INFJ\" or \"ENFP\".\n",
    "\n",
    "Source: <a href=\"https://en.wikipedia.org/wiki/Myers%E2%80%93Briggs_Type_Indicator\" target=\"_blank\">https://en.wikipedia.org/wiki/Myers%E2%80%93Briggs_Type_Indicator</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: <a href=\"https://www.kaggle.com/datasnaek/mbti-type\" target=\"_blank\">https://www.kaggle.com/datasnaek/mbti-type</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"mbti_dataset.csv\",encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4  ENTJ  'You're fired.|||That's another silly misconce..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Labels enconding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = df[\"type\"].unique()\n",
    "for idx,mbti in enumerate(types):\n",
    "    df[\"type\"]= df[\"type\"].replace(mbti,idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['INFJ' 'ENTP' 'INTP' 'INTJ' 'ENTJ' 'ENFJ' 'INFP' 'ENFP' 'ISFP' 'ISTP'\n",
      " 'ISFJ' 'ISTJ' 'ESTP' 'ESFP' 'ESTJ' 'ESFJ']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6     1832\n",
       "0     1470\n",
       "2     1304\n",
       "3     1091\n",
       "1      685\n",
       "7      675\n",
       "9      337\n",
       "8      271\n",
       "4      231\n",
       "11     205\n",
       "5      190\n",
       "10     166\n",
       "12      89\n",
       "13      48\n",
       "15      42\n",
       "14      39\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(types)\n",
    "df[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preprocessing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "#create an object of class PorterStemmer\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanData(posts):\n",
    "    # Lowercase\n",
    "    clean_text = posts.lower()\n",
    "    #remove all hyperlinks\n",
    "    clean_text = re.sub(r'(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})','',clean_text)\n",
    "    word_list = word_tokenize(clean_text)\n",
    "    clean_posts = []\n",
    "    for word in word_list:\n",
    "        if word.isalpha() and word not in stop_words:\n",
    "            word = porter.stem(word)\n",
    "            clean_posts.append(word)\n",
    "    return clean_posts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"posts_preprocessed\"]= df[\"posts\"].apply(lambda row: cleanData(row))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing data analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We group the posts with the same type in order to detect the most used commun words for each type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts_grouped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[intj, moment, sportscent, top, ten, play, exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[find, lack, post, bore, posit, often, exampl,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[one, cours, say, know, bless, absolut, posit,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[intp, enjoy, convers, day, esoter, gab, natur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[anoth, silli, misconcept, approach, logic, go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>[went, break, month, ago, togeth, year, plan, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[think, agre, person, consid, alpha, beta, fox...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>[want, go, trip, without, stay, behind, would,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>[paint, without, guess, istp, best, bud, esfp,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>[got, read, enneagram, though, read, somewher,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>[love, feel, affection, one, love, care, care,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>[univers, graviti, law, mean, serious, would, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>[splinter, cell, blacklist, xbox, gener, well,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>[forgot, board, current, read, fowl, etern, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>[catch, although, quit, terribl, estj, fi, dev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>[esfj, origin, mistyp, nfp, think, increasingl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type                                      posts_grouped\n",
       "0      0  [intj, moment, sportscent, top, ten, play, exp...\n",
       "1      1  [find, lack, post, bore, posit, often, exampl,...\n",
       "2      2  [one, cours, say, know, bless, absolut, posit,...\n",
       "3      3  [intp, enjoy, convers, day, esoter, gab, natur...\n",
       "4      4  [anoth, silli, misconcept, approach, logic, go...\n",
       "5      5  [went, break, month, ago, togeth, year, plan, ...\n",
       "6      6  [think, agre, person, consid, alpha, beta, fox...\n",
       "7      7  [want, go, trip, without, stay, behind, would,...\n",
       "8      8  [paint, without, guess, istp, best, bud, esfp,...\n",
       "9      9  [got, read, enneagram, though, read, somewher,...\n",
       "10    10  [love, feel, affection, one, love, care, care,...\n",
       "11    11  [univers, graviti, law, mean, serious, would, ...\n",
       "12    12  [splinter, cell, blacklist, xbox, gener, well,...\n",
       "13    13  [forgot, board, current, read, fowl, etern, co...\n",
       "14    14  [catch, although, quit, terribl, estj, fi, dev...\n",
       "15    15  [esfj, origin, mistyp, nfp, think, increasingl..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped = df.groupby('type')['posts_preprocessed'].apply(list).reset_index(name='posts_grouped')\n",
    "df_grouped['posts_grouped'] = df_grouped['posts_grouped'].apply(lambda row: [y for x in row for y in x]) # Flatten list\n",
    "df_grouped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_important_words(post_preprocessed):\n",
    "    \n",
    "    w=dict.fromkeys(post_preprocessed,0)\n",
    "    for i in post_preprocessed:\n",
    "        w[i]=w[i]+1\n",
    "    data_sorted = {k: v for k, v in sorted(w.items(), key=lambda x: x[1],reverse=True)}\n",
    "    return data_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We create a descending order dictionnary: each word as a key and the number of accurrences as a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     {'like': 12861, 'think': 10235, 'peopl': 8405,...\n",
       "1     {'like': 5805, 'think': 4563, 'peopl': 3602, '...\n",
       "2     {'like': 10546, 'think': 8421, 'peopl': 6831, ...\n",
       "3     {'like': 8517, 'think': 6513, 'peopl': 5759, '...\n",
       "4     {'like': 1846, 'think': 1471, 'peopl': 1181, '...\n",
       "5     {'like': 1759, 'think': 1396, 'peopl': 1169, '...\n",
       "6     {'like': 16990, 'think': 12980, 'peopl': 10261...\n",
       "7     {'like': 6501, 'think': 4633, 'enfp': 3779, 'p...\n",
       "8     {'like': 2541, 'think': 1766, 'realli': 1288, ...\n",
       "9     {'like': 2696, 'think': 1965, 'get': 1732, 'pe...\n",
       "10    {'like': 1534, 'think': 1216, 'isfj': 930, 'pe...\n",
       "11    {'like': 1798, 'think': 1226, 'istj': 939, 'pe...\n",
       "12    {'like': 803, 'think': 564, 'get': 514, 'estp'...\n",
       "13    {'like': 380, 'think': 292, 'peopl': 220, 'kno...\n",
       "14    {'like': 292, 'think': 269, 'estj': 213, 'peop...\n",
       "15    {'like': 411, 'esfj': 365, 'think': 352, 'peop...\n",
       "Name: dictionnary, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped['dictionnary'] = df_grouped['posts_grouped'].apply(lambda row: select_important_words(row))\n",
    "df_grouped[\"dictionnary\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We select the 20 most frequent words for each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [like, think, peopl, feel, infj, know, one, ge...\n",
       "1     [like, think, peopl, entp, one, get, would, kn...\n",
       "2     [like, think, peopl, would, one, intp, get, kn...\n",
       "3     [like, think, peopl, intj, would, one, know, g...\n",
       "4     [like, think, peopl, entj, get, would, one, kn...\n",
       "5     [like, think, peopl, feel, enfj, know, get, re...\n",
       "6     [like, think, peopl, feel, realli, know, infp,...\n",
       "7     [like, think, enfp, peopl, know, get, feel, re...\n",
       "8     [like, think, realli, peopl, feel, get, know, ...\n",
       "9     [like, think, get, peopl, would, know, istp, o...\n",
       "10    [like, think, isfj, peopl, get, would, know, r...\n",
       "11    [like, think, istj, peopl, would, get, know, o...\n",
       "12    [like, think, get, estp, peopl, know, one, typ...\n",
       "13    [like, think, peopl, know, get, realli, would,...\n",
       "14    [like, think, estj, peopl, would, know, get, o...\n",
       "15    [like, esfj, think, peopl, type, know, get, fe...\n",
       "Name: most_frequent_words, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped[\"most_frequent_words\"]=df_grouped[\"dictionnary\"].apply(lambda row: list(row.keys())[0:20])\n",
    "df_grouped[\"most_frequent_words\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We group the most frequent words for all type and create a dictionnary with occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'like': 15,\n",
       "         'think': 15,\n",
       "         'peopl': 15,\n",
       "         'feel': 15,\n",
       "         'infj': 1,\n",
       "         'know': 15,\n",
       "         'one': 15,\n",
       "         'get': 15,\n",
       "         'would': 15,\n",
       "         'realli': 15,\n",
       "         'thing': 15,\n",
       "         'time': 15,\n",
       "         'say': 15,\n",
       "         'person': 14,\n",
       "         'go': 15,\n",
       "         'make': 15,\n",
       "         'want': 15,\n",
       "         'love': 7,\n",
       "         'type': 14,\n",
       "         'much': 7,\n",
       "         'entp': 1,\n",
       "         'see': 7,\n",
       "         'way': 1,\n",
       "         'intp': 1,\n",
       "         'use': 2,\n",
       "         'intj': 1,\n",
       "         'entj': 1,\n",
       "         'good': 1,\n",
       "         'enfj': 1,\n",
       "         'friend': 6,\n",
       "         'infp': 1,\n",
       "         'enfp': 1,\n",
       "         'isfp': 1,\n",
       "         'istp': 1,\n",
       "         'someth': 1,\n",
       "         'isfj': 1,\n",
       "         'istj': 1,\n",
       "         'estp': 1,\n",
       "         'esfp': 1,\n",
       "         'estj': 1})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total=[]\n",
    "for i in range(0,len(types)-1):\n",
    "    total = total + df_grouped[\"most_frequent_words\"][i]\n",
    "most_freq_dict=Counter(total)\n",
    "most_freq_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the word \"like\" is one of the most frequent words for the 15 types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We create a list with the words which appear as a one of the most frequent words for at least 11 types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['like',\n",
       " 'think',\n",
       " 'peopl',\n",
       " 'feel',\n",
       " 'know',\n",
       " 'one',\n",
       " 'get',\n",
       " 'would',\n",
       " 'realli',\n",
       " 'thing',\n",
       " 'time',\n",
       " 'say',\n",
       " 'person',\n",
       " 'go',\n",
       " 'make',\n",
       " 'want',\n",
       " 'love',\n",
       " 'type',\n",
       " 'much',\n",
       " 'see']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_delete=[]\n",
    "for i in most_freq_dict:\n",
    "    if most_freq_dict[i]>6:\n",
    "        words_to_delete.append(i)\n",
    "words_to_delete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Filtering preprocessing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"posts_preprocessed_filtered\"]= df[\"posts_preprocessed\"].apply(lambda row: [w for w in row if not w in words_to_delete])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>posts_preprocessed</th>\n",
       "      <th>posts_preprocessed_filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>[intj, moment, sportscent, top, ten, play, exp...</td>\n",
       "      <td>[intj, moment, sportscent, top, ten, play, exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>[find, lack, post, bore, posit, often, exampl,...</td>\n",
       "      <td>[find, lack, post, bore, posit, often, exampl,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>[one, cours, say, know, bless, absolut, posit,...</td>\n",
       "      <td>[cours, bless, absolut, posit, best, friend, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>[intp, enjoy, convers, day, esoter, gab, natur...</td>\n",
       "      <td>[intp, enjoy, convers, day, esoter, gab, natur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>[anoth, silli, misconcept, approach, logic, go...</td>\n",
       "      <td>[anoth, silli, misconcept, approach, logic, ke...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts  \\\n",
       "0     0  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...   \n",
       "1     1  'I'm finding the lack of me in these posts ver...   \n",
       "2     2  'Good one  _____   https://www.youtube.com/wat...   \n",
       "3     3  'Dear INTP,   I enjoyed our conversation the o...   \n",
       "4     4  'You're fired.|||That's another silly misconce...   \n",
       "\n",
       "                                  posts_preprocessed  \\\n",
       "0  [intj, moment, sportscent, top, ten, play, exp...   \n",
       "1  [find, lack, post, bore, posit, often, exampl,...   \n",
       "2  [one, cours, say, know, bless, absolut, posit,...   \n",
       "3  [intp, enjoy, convers, day, esoter, gab, natur...   \n",
       "4  [anoth, silli, misconcept, approach, logic, go...   \n",
       "\n",
       "                         posts_preprocessed_filtered  \n",
       "0  [intj, moment, sportscent, top, ten, play, exp...  \n",
       "1  [find, lack, post, bore, posit, often, exampl,...  \n",
       "2  [cours, bless, absolut, posit, best, friend, c...  \n",
       "3  [intp, enjoy, convers, day, esoter, gab, natur...  \n",
       "4  [anoth, silli, misconcept, approach, logic, ke...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Vectorization**\n",
    "\n",
    " * CountVectorizer\n",
    " * TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[\"posts_preprocessed\"].map(' '.join)\n",
    "y=df[\"type\"]\n",
    "\n",
    "cnt_vector = cv.fit_transform(X)\n",
    "X_train,X_test,y_train,y_test = train_test_split(cnt_vector,y,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vector = tfidf.fit_transform(X)\n",
    "X_train_tfidf,X_test_tfidf,y_train_tfidf,y_test_tfidf = train_test_split(tfidf_vector,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filtered=df[\"posts_preprocessed_filtered\"].map(' '.join)\n",
    "\n",
    "tfidf_vector_filtered = tfidf.fit_transform(X_filtered)\n",
    "X_train_tfidf_filtered,X_test_tfidf_filtered,y_train_tfidf_filtered,y_test_tfidf_filtered = train_test_split(tfidf_vector_filtered,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Prediction***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 1:** Preprocessed data + CountVectorizer + LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        INFJ       0.50      0.62      0.55       264\n",
      "        ENTP       0.55      0.46      0.50       147\n",
      "        INTP       0.54      0.57      0.56       256\n",
      "        INTJ       0.50      0.50      0.50       206\n",
      "        ENTJ       0.45      0.32      0.37        53\n",
      "        ENFJ       0.33      0.27      0.30        41\n",
      "        INFP       0.58      0.64      0.61       369\n",
      "        ENFP       0.53      0.50      0.51       145\n",
      "        ISFP       0.36      0.30      0.32        54\n",
      "        ISTP       0.42      0.43      0.43        67\n",
      "        ISFJ       0.41      0.40      0.41        35\n",
      "        ISTJ       0.31      0.21      0.25        42\n",
      "        ESTP       0.73      0.36      0.48        22\n",
      "        ESFP       0.00      0.00      0.00        14\n",
      "        ESTJ       0.50      0.12      0.20         8\n",
      "        ESFJ       0.20      0.08      0.12        12\n",
      "\n",
      "    accuracy                           0.52      1735\n",
      "   macro avg       0.43      0.36      0.38      1735\n",
      "weighted avg       0.51      0.52      0.51      1735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC().fit(X_train,y_train)\n",
    "\n",
    "predictions=model.predict(X_test)\n",
    "\n",
    "classification = metrics.classification_report(y_test,predictions, target_names= types)\n",
    "\n",
    "\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 2:** Preprocessed data + TfidfVectorizer + LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        INFJ       0.66      0.67      0.67       305\n",
      "        ENTP       0.64      0.67      0.65       130\n",
      "        INTP       0.64      0.73      0.68       260\n",
      "        INTJ       0.58      0.60      0.59       200\n",
      "        ENTJ       0.75      0.41      0.53        44\n",
      "        ENFJ       0.78      0.47      0.58        30\n",
      "        INFP       0.66      0.79      0.72       386\n",
      "        ENFP       0.66      0.59      0.62       126\n",
      "        ISFP       0.54      0.46      0.50        57\n",
      "        ISTP       0.70      0.61      0.65        61\n",
      "        ISFJ       0.95      0.49      0.64        39\n",
      "        ISTJ       0.67      0.39      0.49        56\n",
      "        ESTP       0.62      0.29      0.40        17\n",
      "        ESFP       0.00      0.00      0.00         6\n",
      "        ESTJ       1.00      0.25      0.40         8\n",
      "        ESFJ       0.67      0.20      0.31        10\n",
      "\n",
      "    accuracy                           0.65      1735\n",
      "   macro avg       0.66      0.48      0.53      1735\n",
      "weighted avg       0.65      0.65      0.64      1735\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierremecchia/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC().fit(X_train_tfidf,y_train_tfidf)\n",
    "\n",
    "predictions2=model.predict(X_test_tfidf)\n",
    "\n",
    "classification2 = metrics.classification_report(y_test_tfidf,predictions2, target_names= types)\n",
    "\n",
    "\n",
    "print(classification2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 3:** Filtered Preprocessed data + TfidfVectorizer + LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        INFJ       0.62      0.64      0.63       283\n",
      "        ENTP       0.69      0.49      0.57       146\n",
      "        INTP       0.59      0.74      0.65       242\n",
      "        INTJ       0.55      0.70      0.61       197\n",
      "        ENTJ       0.61      0.40      0.48        35\n",
      "        ENFJ       0.60      0.35      0.44        34\n",
      "        INFP       0.68      0.80      0.73       391\n",
      "        ENFP       0.75      0.64      0.69       157\n",
      "        ISFP       0.54      0.30      0.38        50\n",
      "        ISTP       0.79      0.59      0.67        75\n",
      "        ISFJ       0.73      0.38      0.50        29\n",
      "        ISTJ       0.67      0.44      0.53        41\n",
      "        ESTP       0.70      0.29      0.41        24\n",
      "        ESFP       0.00      0.00      0.00        11\n",
      "        ESTJ       0.25      0.10      0.14        10\n",
      "        ESFJ       0.75      0.30      0.43        10\n",
      "\n",
      "    accuracy                           0.64      1735\n",
      "   macro avg       0.59      0.45      0.49      1735\n",
      "weighted avg       0.64      0.64      0.63      1735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC().fit(X_train_tfidf_filtered,y_train_tfidf_filtered)\n",
    "\n",
    "predictions3=model.predict(X_test_tfidf_filtered)\n",
    "\n",
    "classification3 = metrics.classification_report(y_test_tfidf_filtered,predictions3, target_names= types,zero_division=0)\n",
    "\n",
    "print(classification3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the filtering doesn't improve the f1-score result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach is not good. None of the 3 models fit the problem.\n",
    "The idea is not make a prediction for each category seperately. \n",
    "Have a look at the <a href=\"https://github.com/pmecchia/mbti_prediction/blob/master/model%20improvement.ipynb\">model improvement notebook.</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
